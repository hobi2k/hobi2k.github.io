---
layout: post
title:  "Style-Bert-VITS2 학습기 2"
date:   2025-12-10 00:10:22 +0900
categories: Style-Bert-VITS2
---

# Style-Bert-VITS2 학습 로드맵

## STEP 0 - 만들고자 하는 것

만들 시스템

입력

……ねえ。
ほんとに、私でいいの？


출력

일본어 목소리
- 약간 불안함
- 말 중간에 망설임
- 자연스러운 일본어 억양


이를 위해 TTS 모델이 실제로 해야 할 일은 단 3가지다.

- 어디서 끊어 읽을지 (리듬)
- 어떤 분위기로 읽을지 (스타일/감정)
- 어떤 목소리로 소리를 낼지 (음색)

Style-Bert-VITS2는 이 3가지를 각각 다른 모듈로 나눠서 처리한다.

## STEP 1 — TextEncoder: “발화를 설계하는 곳”

이 단계는 가장 중요하다
Style-Bert-VITS2의 70%는 여기서 결정된다.

### TextEncoder의 역할

TextEncoder는 문장을 어떻게 말할지에 대한 ‘발화 설계도’를 만든다.
즉, 여기서는 아직 소리를 만들지 않는다.

여기서 결정되는 것:

- 말의 전체적인 리듬
- 어느 단어를 길게/짧게 읽을지
- 문장이 차분한지, 급한지, 망설이는지
- 감정의 방향 (불안, 평온, 공격적 등)

TextEncoder 출력은 ‘설계도’다.

### 그래서 입력이 많다

Style-Bert-VITS2의 TextEncoder는 여러 정보를 한꺼번에 받는다.

입력

1. 텍스트 토큰 (text tokens)

- “무슨 말을 할지”
- 가장 기본적인 정보

2. tone 정보

- 일본어 억양/악센트용
- 고저 패턴, 장단

3. language ID

- 다국어 대비용
- 일본어만 쓰면 사실상 고정값

4. BERT 문맥 특징

- 이 문장이 어떤 상황에서 나온 말인지

5. style vector

- “지금 감정 상태가 무엇인가”

### 이 입력들은 어떻게 쓰일까?

중요한 사실 하나:

*Style-Bert-VITS2는 이 모든 입력을 ‘더해서(sum)’ 쓴다.*

왜 이게 중요하냐?

- 조건들이 따로 놀지 않는다
- Transformer는 이 모든 정보를 동시에 고려한다

즉, 다음 세 가지를 한 번에 고려한 발화 설계도를 만든다.

- “문맥상 망설임”
- “스타일은 불안”
- “억양은 일본어 특유의 패턴”

## STEP 2 - 왜 일본어 TTS에 BERT가 필요한가

### 예제

다음 두 문장을 보자.

```
ねえ、いい？
```

```
ねえ……いい？
```

질문

- 발음이 다른가?
  - 거의 아니다.

- 사람이 말할 때 느낌이 같은가?
  - 완전히 다르다.

### 기존 TTS의 한계

기존 TTS는 보통 이런 정보만 본다.

- 음소(phoneme)
- 악센트 기호
- 간단한 문장 부호

그래서:

- ……이 의미하는 “침묵”
- “주저함”
- “불안”

같은 맥락 정보를 제대로 이해하지 못한다.

### BERT의 역할

BERT는 “이 문장이 어떤 상황에서 나온 말인지 요약해주는 뇌”다.

BERT는 다음을 잘 잡아낸다.

- 말이 이어지는 흐름
- 문장 앞뒤 관계
- 강조, 망설임, 반복

그리고 이를 숫자 벡터로 요약해서 TTS에 넘긴다.

### BERT가 없으면 생기는 문제

- 말줄임표가 있어도 평범하게 읽힘
- 같은 문장을 항상 같은 톤으로 읽음
- 캐릭터 연기가 약해짐

## STEP 3 - Style Vector: 감정 조절 노브

### style vector의 역할

“같은 사람이, 같은 말을, 어떤 상태로 말하느냐”

예를 들면:

- 같은 인물
- 같은 문장
- 하지만:
  - 평온
  - 불안
  - 분노
  - 속삭임

이 차이를 **숫자 하나(256차원)**로 요약한 게 style vector다.

### 중요한 특징

- style vector는 시간 축이 없다
- 즉, 문장 전체에 적용된다

그래서:

- 문장 중간에 감정이 바뀌는 것은 LLM 텍스트 설계 영역

## STEP 4 - Alignment / Duration

이 단계는 “아, 여긴 건드릴 곳이 아니구나”를 이해하는 단계다.

### 문제 상황

텍스트

- ね え

오디오

- 0.2초 0.8초

누가 얼마나 길게 발음될지 알아야 한다.

## 이것을 담당하는 것들

- Duration Predictor
- MAS (Monotonic Alignment Search)

이것들은 “텍스트를 시간으로 늘려주는 장치”다

### 신경을 안 쓰는 이유

잘 학습된 모델에서는 이미 안정적

잘못 건드리면:

- 발음 반복
- 말 끊김
- 음성 붕괴

## STEP 5 - Posterior / Flow / Generator: 음성 엔진

이 단계는 “엔진실”이라고 생각할 수 있다.

### PosteriorEncoder

- 학습 때만 등장
- 정답 음성을 **압축 표현(z)**으로 변환
- 추론할 때는 아예 사용하지 않는다.

### Flow

- 두 세계를 이어준다
  - 텍스트에서 예측한 z
  - 실제 음성에서 나온 z

분포를 맞추는 장치

### Generator

- z -> 실제 음파
- 음질과 음색에 가장 큰 영향