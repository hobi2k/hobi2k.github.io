---
layout: post
title:  "Healtheat 이미지 인식 프로젝트 - 협업일지 12"
date:   2025-12-22 00:10:22 +0900
categories: Healtheat_Vision
---

# 12월 22일 협업일지

날짜: 2024-12-22
이름: 안호성
팀명: 4팀

## 오늘 맡은 역할 및 작업 내용

오늘은 기능 구현보다는 프로젝트 정리, 전달 단계에 집중한 날이었다.
그동안 개발해 온 이미지 증강 파이프라인과 멀티모달 알약 인식 데모 시스템을
팀 외부에서도 이해할 수 있도록 문서화 및 보고서 자료 작성을 수행했다.

1. README 문서 갱신

- 기존 README 상태
    - 프로젝트 초기 구조 위주의 간단한 설명만 존재
    - 증강 파이프라인, 멀티모달 데모에 대한 설명 부족
- 오늘 작업
    - 프로젝트 전체 흐름 기준으로 README 재구성
    - 다음 내용 중심으로 갱신
        - Diffusion + SAM 기반 이미지 증강 파이프라인
        - 멀티모달 알약 인식 데모(YOLO + Qwen + TTS)

2. 보고서 자료 - 이미지 증강 파트 작성

- Diffusion 기반 이미지 증강을 보고서용으로 정리
- 포함 내용
    - 왜 일반적인 이미지 생성이 위험한지
    - YOLO 증강과 Diffusion 증강의 차이
    - SAM + background inpainting 전략
    - 알약 객체를 보존하면서 배경만 증강하는 구조 설명
- 강조 포인트
    - 생성 모델을 제어된 방식으로 활용했다는 점
    - 단순 성능 욕심이 아니라 데이터 정합성을 최우선으로 고려했다는 설계 의도

3. 보고서 자료 - 멀티모달 데모 파트 작성

- 멀티모달 알약 인식 시스템을 보고서용으로 정리
- 구성
    - YOLO: 알약 탐지
    - Qwen: 탐지 결과 + 위치, 알약 정보 기반 설명 생성
    - TTS(SpeechT5 / VITS): 음성 출력
- 작성 포인트
    - 단순 모델 나열이 아니라 **“하나의 사용자 경험 흐름”**으로 설명
    - 이미지 입력 -> 인식 -> 설명 -> 음성 출력까지의 전체 파이프라인 강조
- 결과
    - 기술 데모가 아니라 제품 프로토타입 관점에서 설명 가능한 자료 완성

## 오늘 작업 현황

오늘은 코드 생산량은 적었지만, 프로젝트 완성도를 크게 끌어올린 날이었다.

- README 갱신으로 리포지토리의 가독성과 전달력이 개선됨
- 보고서 자료 작성으로 증강 파트와 멀티모달 데모 파트의 기술적 의도가 명확해짐

## 오늘 협업 중 제안하거나 피드백한 내용

- 팀원들에게 증강, 멀티모달 파트는 설계를 설명하지 않으면 오해될 수 있음을 강조

## 오늘 분석/실험 중 얻은 인사이트나 발견한 문제점

- 프로젝트 후반부로 갈수록 기술 구현보다 정리, 설명 능력이 더 중요해짐

## 일정 지연이나 협업 중 어려웠던 점

- 그동안 진행한 작업량이 많아 어떤 내용을 어디까지 문서에 포함할지 선별하는 데 시간이 필요했음

## 오늘 발표 준비나 커뮤니케이션에서 기여한 부분

- 보고서 자료에서 증강 파트와 멀티모달 데모 파트를 담당하여 기술 설명 역할 수행