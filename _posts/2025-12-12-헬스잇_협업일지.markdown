---
layout: post
title:  "Healtheat 이미지 인식 프로젝트 - 협업일지 6"
date:   2025-12-11 00:10:22 +0900
categories: Healtheat_Vision
---

# 12월 12일 협업일지

날짜: 2024-12-12
이름: 안호성
팀명: 4팀

## 오늘 맡은 역할 및 작업 내용

오늘은 기존 자동 라벨링 파이프라인을 확장하여
YOLO + SAM(Segment Anything Model) 결합 방식을 실험했고,
그 결과를 통해 현재 프로젝트에서 YOLO 단독 사용이 가장 합리적이라는 결론에 도달했다.

1. YOLO + SAM 기반 자동 라벨링 확장 시도

- 목적
    - YOLO 기반 pseudo-labeling에서 bounding box 내부 객체 경계를 더 정밀하게 보정하기 위해 SAM을 활용한 segmentation 기반 보조 라벨링을 시도

- 접근 개요
    - YOLO로 객체 후보 영역(bbox) 검출
    - 해당 영역 또는 전체 이미지에 대해 SAM으로 mask 생성
    - mask 결과를 이용해:
        - bbox 보정
        - 누락 객체 보완
        - pseudo-label 품질 향상
    - 을 기대하며 자동 라벨링 파이프라인에 결합 시도

2. 결과: 성능 하락 (과도한 검출)

- 실험 결과
    - 모델 성능이 오히려 하락
    - Kaggle 기준 성능 및 정성적 검증 모두에서 개선 효과 없음

- 주요 원인 분석
    - SAM 모델의 성능이 지나치게 우수하여
    - 알약뿐 아니라 배경, 포장지, 그림자, 반사 영역 등까지 객체로 분리하는 문제가 발생
    - 결과적으로:
        - 알약 detection이라는 과업의 scope가 무너짐
        - pseudo-label 단계에서 noise label이 급증
        - YOLO가 학습해야 할 “정확한 객체 개념”이 오염됨

## 오늘 작업 현황

YOLO + SAM 결합 실험은 성공적이지 못했다.
하지만 이를 통해 “더 강한 모델을 붙이면 항상 성능이 오른다”는 가정이 틀렸음을 확인했다.

현재 데이터셋 규모, 특성에서는 YOLO 단독 detection이 가장 안정적이고 효과적이라는 결론을 도출했다.

## 오늘 협업 중 제안하거나 피드백한 내용

팀원들에게 SAM은 general-purpose segmentation에는 매우 강력하지만
본 프로젝트처럼 class가 명확히 정의된 detection 문제에서는 오히려 noise를 유발할 수 있다는 점을 공유했다.

## 오늘 분석/실험 중 얻은 인사이트나 발견한 문제점

- 알약 인식 문제의 핵심은:
    - 객체를 “많이 잡는 것”이 아니라
    - 정확한 객체만 일관되게 잡는 것

- SAM은:
    - object discovery에는 탁월하지만
    - object selection에는 별도의 제약 조건이 필요

- 현재 프로젝트 조건에서는:
    - YOLO 단독 + 데이터 품질 개선이
    - YOLO + 외부 모델 결합(CLIP, SAM)보다 훨씬 효과적임을 확인

## 일정 지연이나 협업 중 어려웠던 점

- SAM 결합 실험이 예상보다 많은 시간 대비 성과가 없었음
- pseudo-label 결과를 다시 정리하고 되돌리는 과정이 필요했음
- 실험 코드 정리 및 파이프라인 복구에 추가 작업 발생

## 오늘 발표 준비나 커뮤니케이션에서 기여한 부분

- YOLO + SAM 실험 결과와 실패 원인을 팀원에게 공유
- “왜 YOLO 단독 전략이 현재 최선인지”를 실험 기반 근거로 설명하여 팀 내 방향성을 정리함

## 내일 목표 / 할 일

- Diffusion 이미지 증강 시도