---
layout: post
title:  "허깅페이스 MCP 코스 - MCP(Model Context Protocol) 핵심 개념·용어 정리"
date:   2025-01-13 00:10:22 +0900
categories: Huggingface_mcp
---

# MCP(Model Context Protocol) 핵심 개념·용어 정리

## MCP란 무엇인가

MCP(Model Context Protocol)는 **AI 애플리케이션(Host)이 외부 도구·데이터·워크플로우(Server)를 표준화된 방식으로 연결**하기 위한 프로토콜이다. 여기서는 이를 “**AI 애플리케이션의 USB-C**”로 비유한다.

- USB-C가 다양한 주변기기(키보드, 디스플레이, 저장장치 등)를 **하나의 규격**으로 연결하듯,
- MCP는 AI 모델(LLM)이 필요한 외부 기능(툴 실행, 데이터 조회, 프롬프트 템플릿 등)을 **일관된 프로토콜**로 연결한다.

### MCP가 표준화로 주는 이점(생태계 관점)
- **사용자**: 앱마다 제각각인 연결/설정/사용 경험이 줄어들고, 더 일관된 UX를 얻는다.
- **AI 앱 개발자**: 매번 툴/데이터 소스에 맞춰 커스텀 통합을 만드는 대신, MCP 클라이언트를 한 번 구현해 여러 서버와 연동할 수 있다.
- **툴·데이터 제공자**: 특정 앱 전용 API를 여러 개 만들지 않고, MCP 서버 구현 1회로 다양한 Host에서 재사용될 수 있다.
- **생태계 전체**: 상호운용성(interoperability)이 높아지고, 파편화(fragmentation)가 줄어 혁신이 쉬워진다.

## MCP가 해결하는 통합 문제: M×N Integration Problem

### 문제 정의
**M×N 통합 문제**란,
- M개의 서로 다른 AI 애플리케이션이 있고
- N개의 서로 다른 외부 도구/데이터 소스가 있을 때
표준이 없다면 **모든 조합마다 개별 통합이 필요**해지는 구조적 문제를 말한다.

즉, 통합 수가 **M×N**으로 증가한다.

### MCP 없이: “M×N” 구조의 현실적 비용
MCP 같은 표준이 없으면, 각 AI 앱은 각 도구/데이터에 대해 다음을 각각 구현해야 한다.
- 인증 방식, 요청/응답 포맷, 에러 처리
- 버전 변경 대응, 유지보수 및 테스트
- 기능 스펙 문서화 및 개발자 온보딩

결과적으로:
- **개발 마찰(friction)** 증가
- **유지보수 비용** 증가
- 도구/모델이 늘어날수록 통합이 **기하급수적으로** 복잡해짐
- 인터페이스가 제각각이라 **확장성**이 떨어짐

### MCP 적용: “M+N” 구조로 전환
MCP는 통합을 다음처럼 재구성한다.

- 각 AI 애플리케이션은 **MCP Client를 한 번만 구현**한다. (Host 내부 구성요소)
- 각 툴/데이터 제공자는 **MCP Server를 한 번만 구현**한다.
- 이후 Host는 표준 프로토콜로 서버들과 연결하므로, 통합 총량이 **M×N에서 M+N**으로 감소한다.

핵심은 “모든 조합을 직접 잇는 것”이 아니라,
“**양쪽이 표준 인터페이스만 준수**하도록 설계”한다는 점이다.

## MCP 용어 체계가 중요한 이유

MCP는 HTTP/USB-C처럼 “표준”을 지향한다.
표준은 구현 자체뿐 아니라 **용어를 정확히 공유**해야 생태계가 커질수록 혼선이 줄어든다.

포인트
- 문서화/커뮤니티 커뮤니케이션에서 용어를 정확히 사용해야
- Host/Client/Server 책임 경계가 명확해지고
- 구현·디버깅·확장 시 오류 가능성이 줄어든다.

## MCP의 핵심 구성요소(Components)

MCP는 HTTP의 클라이언트-서버 관계처럼 **Host/Client/Server** 구조를 가진다.

### Host
**Host**는 사용자가 직접 상호작용하는 **사용자-facing AI 애플리케이션**이다.

- 예시:
  - 데스크톱 AI 앱(예: Claude Desktop류)
  - AI IDE(예: Cursor 같은 IDE 계열)
  - inference 라이브러리(Hugging Face Python SDK 등)
  - LangChain, smolagents 같은 라이브러리로 만든 커스텀 앱

Host의 책임:
- 유저 입력을 받고(UX)
- LLM 호출을 수행하며
- 필요 시 MCP Server에 연결하여 도구/데이터를 사용하고
- 전체 오케스트레이션(흐름 제어)을 담당한다.

즉 Host는 “앱 전체”이고, MCP는 Host가 외부 세계와 연결되는 표준 통로다.

### Client
**Client**는 Host 내부에 존재하는 **MCP 통신 담당 컴포넌트**다.

- 특징: **Client는 특정 Server와 1:1 연결**을 유지한다.
- 역할:
  - MCP 프로토콜 레벨의 통신 관리
  - 메시지 포맷/핸드셰이크/요청-응답 처리
  - Host 로직과 Server 사이의 중계자 역할

주의점:
- 많은 자료가 Host와 Client를 혼용하지만,
  - **Host = 앱(사용자-facing)**
  - **Client = Host 내부의 MCP 통신 모듈**
로 기술적으로 구분해야 한다.

### Server
**Server**는 Host 외부에 있는 프로그램/서비스로,
MCP를 통해 기능을 제공한다.

- Server가 노출하는 대표 기능 범주:
  - Tools
  - Resources
  - Prompts
  - (추가로) Sampling

서버는 “도구 제공자/데이터 제공자” 입장에서 구현 대상이며,
표준 MCP 인터페이스로 다양한 Host에서 재사용 가능해진다.

## MCP가 제공하는 Capability(기능) 분류

MCP는 “AI 앱의 가치 = 제공하는 capability의 합”이라는 관점에서,
외부 기능을 표준 단위로 나눠 다룬다.

대표 capability는 4가지다.

### Tools (실행 가능한 함수)
**Tools**는 AI 모델이 호출할 수 있는 **실행형 함수(executable function)**다.

- 성격:
  - “무언가를 수행”하거나
  - “계산된 결과를 반환”하는 기능
- 예시:
  - 날씨 앱의 `get_weather(location)` 같은 함수
  - 코드 실행기(LLM이 작성한 코드를 실행해 결과를 반환)

정리하면 Tools는 “행동(action) 또는 계산(computation)” 중심이다.

### Resources (읽기 전용 데이터)
**Resources**는 중요한 계산 없이, 컨텍스트를 제공하는 **read-only 데이터 소스**다.

- 성격:
  - LLM이 참고할 정보를 제공하지만
  - 툴처럼 실행/연산 중심은 아니다.
- 예시:
  - 연구 보조 앱의 논문/자료 저장소
  - 애플리케이션 문서(Documentation) 리소스

정리하면 Resources는 “컨텍스트(context) 공급” 중심이다.

### Prompts (사전 정의된 템플릿/워크플로우)
**Prompts**는 사용자-LLM-외부 기능의 상호작용을 안내하는 **미리 정의된 템플릿** 또는 워크플로우다.

- 성격:
  - 모델에게 “어떻게 행동할지”를 구조화해 제공
  - 팀/프로덕트 단위로 재사용 가능한 규칙/형식
- 예시:
  - “요약 프롬프트”
  - “코드 스타일 가이드 프롬프트”

정리하면 Prompts는 “지침(instruction)·형식(format) 표준화” 중심이다.

### Sampling (서버 주도 LLM 호출 요청)
**Sampling**은 다소 특이한 개념으로,
Server가 Client/Host에 **LLM 상호작용을 수행해 달라고 요청**할 수 있는 메커니즘이다.

- 의미:
  - “LLM이 한 번 생성하고 끝”이 아니라
  - 서버/워크플로우가 **추가 LLM 호출(재귀적 단계)**을 유도할 수 있음
- 예시(강의):
  - 글쓰기 앱이 초안을 만든 뒤,
    스스로 결과를 검토하고 수정 결정을 내리는 “리뷰 단계”를 다시 수행

정리하면 Sampling은 “서버 주도 재귀(recursive) 상호작용”을 가능하게 한다.

## Capability를 실제로 어떻게 묶어 쓰나: Code Agent 예시

강의는 코드 에이전트(use case)에서 다음처럼 MCP 엔티티를 구성할 수 있다고 설명한다.

- **Tool**: Code Interpreter  
  - LLM이 생성한 코드를 실행해 결과를 얻는다.
- **Resource**: Documentation  
  - 애플리케이션/라이브러리 문서 데이터를 컨텍스트로 제공한다.
- **Prompt**: Code Style  
  - 코드 생성 규칙(스타일/구조/제약)을 안내한다.
- **Sampling**: Code Review  
  - 생성된 코드를 LLM이 다시 검토하고 개선하도록 재귀 단계로 유도한다.

즉 MCP는 단순히 “툴 하나 연결”이 아니라,
- 실행(툴) + 컨텍스트(리소스) + 가이드(프롬프트) + 재귀(샘플링)
를 조합해 **에이전트형 워크플로우**를 표준 단위로 구성하게 해준다.

## 결론: 이 글에서 가져가야 할 핵심

- MCP는 AI 애플리케이션과 외부 기능을 연결하는 **표준 프로토콜**이다.
- 표준이 없을 때 발생하는 **M×N 통합 문제**를,
  Host/Client/Server 분리와 표준 인터페이스로 **M+N 구조**로 바꾼다.
- MCP의 논의는 용어가 중요하며, 특히
  - Host(앱) vs Client(통신 컴포넌트) 혼용을 피해야 한다.
- MCP 서버가 제공하는 capability는 대표적으로
  - Tools(실행 함수)
  - Resources(읽기 데이터)
  - Prompts(템플릿/워크플로우)
  - Sampling(서버 주도 재귀 LLM 호출)
로 정리된다.

참고자료
Huggingface, mcp course, https://huggingface.co/learn