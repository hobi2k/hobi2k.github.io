---
layout: post
title:  "[DL Project] 축구 경기 영상 Semantic Segmentation"
date:   2025-11-27 10:43:22 +0900
categories: DeepLearning
---

# 축구 경기 영상 Semantic Segmentation

## 프로젝트 개요

본 실습은 Kaggle의 Football Semantic Segmentation 데이터셋을 사용해
UNet 및 Attention UNet 모델을 비교, 훈련, 평가하는 작업을 수행한다.

### 문제 정의

영상 속 각 픽셀을 11개 클래스 중 하나로 분류하는 작업.

### 데이터 구조


| 경로                  | 설명                             |
| ------------------- | ------------------------------ |
| `images/*.jpg`      | 원본 이미지                         |
| `images/*fuse*.png` | 라벨(mask) 이미지 – RGB 색상으로 클래스 표현 |


### 사용 모델


| 모델                  | 설명                                                   |
| ------------------- | ---------------------------------------------------- |
| **U-Net**           | Skip-connection 기반 Encoder–Decoder 구조                |
| **Attention U-Net** | Skip feature에 Attention Gate를 적용해 더 중요한 정보만 선택적으로 전달 |

### 평가 지표


| 지표                     | 의미                       |
| ---------------------- | ------------------------ |
| **Cross Entropy Loss** | 픽셀 단위 분류 손실              |
| **Dice Score**         | 분할 품질 평가 지표 (overlap 기준) |


## 데이터 준비 및 전처리

KaggleHub로 다운로드

```python
data_path = kagglehub.dataset_download("sadhliroomyprime/football-semantic-segmentation")
```

이미지 / 마스크 분리

```python
images_list = sorted([i for i in Path.iterdir(Config.IMG_PATH) if i.suffix.lower() == ".jpg"])
masks_list = sorted([f for f in Path.iterdir(Config.IMG_PATH) if "fuse" in str(f)])
```

샘플 이미지 확인

라벨은 RGB 컬러이므로 각 색상이 하나의 클래스에 대응한다.

### 마스크 색상 -> 클래스 ID 매핑

라벨 마스크는 RGB 컬러 기반이므로 이를 클래스 인덱스로 변환해야 한다.

```python
unique_colors = np.unique(mask.reshape(-1,3), axis=0)
col_to_idx_dict = {color: idx for idx, color in enumerate(classes)}
```

## Dataset 설계

핵심 요구사항

- Mask를 RGB -> class index 맵으로 변환
- 이미지와 마스크의 사이즈를 동일하게 Resize
- 학습모드에서는 augmentation 적용

### SoccerDataset

```python
class SoccerDataset:
    def __getitem__(self, idx):
        image = cv2.imread(...)
        mask = cv2.imread(...)

        img_t = self.img_transform(image)
        msk_n = self.mask_transform(mask)

        mask_class = np.zeros((h,w), dtype=np.uint8)
        for color, label in col_dict.items():
            mask_class[(msk_n == color).all(axis=-1)] = label

        return img_t, torch.from_numpy(mask_class).long()
```

데이터 증강

- RandomHorizontalFlip
- Bilinear / Nearest Resize

## 데이터 분리 및 DataLoader

```python
train_split = int(len(images_list) * Config.TRAIN_SPLIT)
val_split   = int(len(images_list) * Config.VAL_SPLIT)

train_dataset = SoccerDataset(x_train, y_train, col_map, train_mode=True)
val_dataset   = SoccerDataset(x_val,   y_val,   col_map)
test_dataset  = SoccerDataset(x_test,  y_test,  col_map)

train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)
```

## 모델링

### UNet 구조 정리

UNet의 핵심 요소

- Encoder: Conv -> Conv -> MaxPool
- Decoder: TransposeConv -> concat -> Conv
- Skip Connection: 해상도 정보를 보완
- 1×1 Conv Output: 각 픽셀당 클래스 로짓 생성

UNet 구현 요약

```python
class MyUNet(nn.Module):
    def __init__(self, num_classes=11):
        super().__init__()
        self.encoder1 = conv_block(3,64)
        self.encoder2 = conv_block(64,128)
        self.encoder3 = conv_block(128,256)

        self.pool = nn.MaxPool2d(2,2)
        self.bottleneck = conv_block(256,512)

        self.upconv3 = nn.ConvTranspose2d(512,256,2,2)
        self.decoder3 = conv_block(512,256)

        self.upconv2 = nn.ConvTranspose2d(256,128,2,2)
        self.decoder2 = conv_block(256,128)

        self.upconv1 = nn.ConvTranspose2d(128,64,2,2)
        self.decoder1 = conv_block(128,64)

        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)
```

### Dice Score

```python
dice = (2 * intersection) / (pred + target)
```

one-hot 기반으로 클래스별 dice를 계산한 뒤 평균.

## UNet 학습

- Loss: CrossEntropyLoss
- Optimizer: Adam
- Early Stopping: 검증 Dice Score 기준, 10번 연속 상승 없으면 종료

학습 루프

```python
for epoch in range(EPOCHS):
    unet.train()
    logits = unet(images)
    loss = loss_fn(logits, masks)
    ...
    val_dice = dice_score(logits, masks)
```

UNet 훈련 결과

- 20 epoch에서 조기 종료
- Train Loss: 0.4757
- Val Loss: 0.8665
- Val Dice Score: 0.4894

## UNet 테스트 결과

- Test Loss: 0.48 ~ 0.55 범위
- Test Dice Score: ≈ 0.49

## UNet 예측 시각화

출력

- 원본 이미지
- GT Mask (컬러맵 적용)
- Predicted Mask

```python
preds = torch.argmax(logits, dim=1)
gt_color = mask_to_color(gt)
pred_color = mask_to_color(pred)
```

## Attention UNet

Attention UNet은 skip connection에 Attention Gate를 적용하여
decoder가 필요한 spatial feature만 선택적으로 전달하게 한다.

### Attention Gate 구조

```python
class AttentionGate(nn.Module):
    def forward(self, g, x):
        g1 = W_g(g)
        x1 = W_x(x)
        psi = sigmoid(conv(relu(g1 + x1)))
        return x * psi
```

### Attention UNet 구조

MyUNet을 상속하여 skip connection 앞에 AttentionGate 추가

```python
class AttentionUNet(MyUNet):
    def forward(self, x):
        e1,e2,e3,...
        e3_att = self.att3(d3, e3)
        e2_att = self.att2(d2, e2)
        e1_att = self.att1(d1, e1)
```

## Attention UNet 훈련 결과

- Epoch 28에서 조기 종료
- Train Loss: 0.4080
- Val Loss: 0.7656
- Val Dice Score: 0.4970

UNet 대비 약 1% 가량 Dice Score 개선됨.

## Attention UNet 테스트 성능

- Test Loss: ≈ 0.40 ~ 0.50
- Test Dice Score: ≈ 0.49 ~ 0.50

## Attention UNet 예측 시각화

-  GT vs Prediction 시각적으로 비교하여 Attention UNet이 복잡한 영역(선수m 경기장 경계 등)을 더 잘 분리함을 확인.

## 결론 및 회고

모델 비교 요약


| 모델                 | Val Dice | Test Dice | 특징                                        |
| ------------------ | -------- | --------- | ----------------------------------------- |
| **U-Net**          | ~0.489   | ~0.49     | 기본 skip-connection 구조                     |
| **Attention UNet** | ~0.497   | ~0.50     | skip feature에 attention 적용 → 미세 구조 복원에 유리 |
