---
layout: post
title:  "Healtheat 이미지 인식 프로젝트 - 협업일지 5"
date:   2025-12-11 00:10:22 +0900
categories: Healtheat_Vision
---

# 12월 11일 협업일지

날짜: 2024-12-11
이름: 안호성
팀명: 4팀

## 오늘 맡은 역할 및 작업 내용

오늘은 기존 AUTOCORRECT(Pseudo-Labeling) 파이프라인을 확장하여
YOLO + CLIP 결합 방식을 시도했고, 그 과정에서 발생한 구조적 한계와 실패 원인을 분석했다.

1. YOLO + CLIP 기반 AUTOCORRECT 확장 시도

- 목적
    - YOLO가 생성한 pseudo-label의 품질을 보완하기 위해
    - CLIP의 이미지–텍스트 유사도 임베딩을 활용해
    - 라벨 신뢰도를 높이거나, 잘못된 클래스를 교정하려는 시도

- 접근 개요
    - YOLO로 검출된 객체 crop 생성
    - 각 crop에 대해 CLIP image embedding 생성
    - 클래스별 텍스트 프롬프트 또는 대표 임베딩과의 유사도 비교
    - 유사도 기반으로 클래스 재할당 또는 검증을 시도

2. 결과: 실패 (Class ID 붕괴)

- 실험 결과, 클래스 ID가 심각하게 망가지는 현상 발생
- 근본 원인 분석:
    - CLIP은 “의미적 유사성” 기반 모델이기 때문에 외형, 색상, 형태가 유사하지만 실제로는 서로 다른 알약 클래스를 구분하지 못함
    - 결과적으로 서로 다른 pill class가 하나의 클러스터로 묶이거나 특정 클래스에 예측이 쏠리는 현상 발생
    - 기존에 유지되던 YOLO class id 체계가 붕괴됨

- 결론
    - CLIP은 open-vocabulary 인식이나 coarse grouping에는 적합하지만
    - 본 프로젝트처럼 *시각적으로 매우 유사하지만 클래스는 명확히 구분되어야 하는 문제*에는 직접적인 class 결정 로직으로 사용하기에는 부적합

## 오늘 작업 현황

YOLO + CLIP 결합을 통한 자동 라벨링 확장 시도는 실험적으로 실패했다.
하지만 단순한 시행착오가 아니라, CLIP의 한계, pill recognition 문제의 난이도, “유사성 기반 모델”과 “정확한 클래스 분류”의 차이를
명확히 체감하고 정리한 의미 있는 실험이었다.

## 오늘 협업 중 제안하거나 피드백한 내용

- Pseudo-Labeling 도입 배경과 데이터 개선 효과를 팀원에게 상세히 공유
- 원시 데이터셋 구조가 팀원에게 불편함을 줄 수 있어 “이미지 1개 = JSON 1개” 구조로 통합한 이유 설명
- 모델 개선 결과(mAP, Kaggle 점수) 공유
- 향후 데이터 정제/교정 자동화 방향성 제안

## 오늘 분석/실험 중 얻은 인사이트나 발견한 문제점

팀원들에게 다음을 공유했다.

- CLIP을 단순히 “정확도를 올려주는 마법의 도구”로 붙이면 안 된다는 점
- 알약 데이터의 특성상 미세한 시각 차이가 클래스 결정에 핵심이라는 점

## 일정 지연이나 협업 중 어려웠던 점

- CLIP 결합 실험이 예상보다 많은 시간 소요 대비 성과가 없었음
- class id 붕괴 이후 데이터셋을 되돌리는 과정이 필요했음
- 실험 자체는 의미 있었으나, 단기적인 성능 개선으로는 이어지지 못함

## 오늘 발표 준비나 커뮤니케이션에서 기여한 부분

- 알약 인식 문제는:
    - 일반 객체 인식보다
    - fine-grained classification 문제에 가깝다.

- CLIP은:
    - “이게 알약이냐?”
    - “이게 대략 어떤 계열이냐?” 에는 강하지만,
    - “이게 정확히 어떤 제품이냐?”에는 취약하다.

- 따라서:
    - YOLO + CLIP 결합은
    - class 결정 단계가 아니라
    - 데이터 정제, 샘플 필터링, 이상치 탐지 쪽으로 재설계해야 한다는 결론에 도달했다.

## 내일 목표 / 할 일

- YOLO + Segment Anything 기반 자동 라벨링